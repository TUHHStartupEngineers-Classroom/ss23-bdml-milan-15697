{
  "hash": "aa7450ee74fa593fefbd5ccd31502d48",
  "result": {
    "markdown": "---\ntitle: \"Challenge - Automated Machine Learning with H20 (II)\"\nauthor: \"Milan Bhardwaj\"\ndate: \"06/04/2023\"\n---\n\n\nLoad the training & test dataset\n\n::: {.cell hash='04_h20_cache/html/unnamed-chunk-1_0057b3d1273266148c739923b204e76b'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.2     ✔ readr     2.1.4\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#> ✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n#> ✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n#> ✔ purrr     1.0.1     \n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlibrary(parsnip)\nlibrary(recipes)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> \n#> Attaching package: 'recipes'\n#> \n#> The following object is masked from 'package:stringr':\n#> \n#>     fixed\n#> \n#> The following object is masked from 'package:stats':\n#> \n#>     step\n```\n:::\n\n```{.r .cell-code}\nlibrary(rsample)\nlibrary(yardstick)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> \n#> Attaching package: 'yardstick'\n#> \n#> The following object is masked from 'package:readr':\n#> \n#>     spec\n```\n:::\n\n```{.r .cell-code}\nlibrary(workflows)\nlibrary(tune)\n```\n:::\n\n\nLoading the Testing and Training Dataset:\n\n::: {.cell hash='04_h20_cache/html/unnamed-chunk-2_4c51e8a29c460446c2e929e206a962d8'}\n\n```{.r .cell-code}\nproduct_dataset <- read_csv(\"../../files/product_backorders.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Rows: 19053 Columns: 23\n#> ── Column specification ────────────────────────────────────────────────────────\n#> Delimiter: \",\"\n#> chr  (7): potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_bu...\n#> dbl (16): sku, national_inv, lead_time, in_transit_qty, forecast_3_month, fo...\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nproduct_dataset_secondary <- product_dataset %>% \n  mutate(\n      product_backorder = went_on_backorder %>% str_to_lower() %>% str_detect(\"yes\") %>% as.numeric()\n  ) %>% \n  select(-c(went_on_backorder))\nglimpse(product_dataset)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Rows: 19,053\n#> Columns: 23\n#> $ sku               <dbl> 1113121, 1113268, 1113874, 1114222, 1114823, 1115453…\n#> $ national_inv      <dbl> 0, 0, 20, 0, 0, 55, -34, 4, 2, -7, 1, 2, 0, 0, 0, 0,…\n#> $ lead_time         <dbl> 8, 8, 2, 8, 12, 8, 8, 9, 8, 8, 8, 8, 12, 2, 12, 4, 2…\n#> $ in_transit_qty    <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0…\n#> $ forecast_3_month  <dbl> 6, 2, 45, 9, 31, 216, 120, 43, 4, 56, 2, 5, 5, 54, 4…\n#> $ forecast_6_month  <dbl> 6, 3, 99, 14, 31, 360, 240, 67, 6, 96, 4, 9, 6, 72, …\n#> $ forecast_9_month  <dbl> 6, 4, 153, 21, 31, 492, 240, 115, 9, 112, 6, 13, 9, …\n#> $ sales_1_month     <dbl> 0, 1, 16, 5, 7, 30, 83, 5, 1, 13, 0, 1, 0, 0, 1, 0, …\n#> $ sales_3_month     <dbl> 4, 2, 42, 17, 15, 108, 122, 22, 5, 30, 2, 5, 4, 0, 3…\n#> $ sales_6_month     <dbl> 9, 3, 80, 36, 33, 275, 144, 40, 6, 56, 3, 8, 5, 0, 4…\n#> $ sales_9_month     <dbl> 12, 3, 111, 43, 47, 340, 165, 58, 9, 76, 4, 11, 6, 0…\n#> $ min_bank          <dbl> 0, 0, 10, 0, 2, 51, 33, 4, 2, 0, 0, 0, 3, 4, 0, 0, 0…\n#> $ potential_issue   <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n#> $ pieces_past_due   <dbl> 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ perf_6_month_avg  <dbl> 0.90, 0.96, 0.81, 0.96, 0.98, 0.00, 1.00, 0.69, 1.00…\n#> $ perf_12_month_avg <dbl> 0.89, 0.97, 0.88, 0.98, 0.98, 0.00, 0.97, 0.68, 0.95…\n#> $ local_bo_qty      <dbl> 0, 0, 0, 0, 0, 0, 34, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, …\n#> $ deck_risk         <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n#> $ oe_constraint     <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n#> $ ppap_risk         <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No…\n#> $ stop_auto_buy     <chr> \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Ye…\n#> $ rev_stop          <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n#> $ went_on_backorder <chr> \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Ye…\n```\n:::\n\n```{.r .cell-code}\n# Splitting the dataset into train and test\nsplit_object<- initial_split(product_dataset_secondary, prop = 0.75)\ntrain_table_final <- training(split_object)\ntest_table_final <- testing(split_object)\n```\n:::\n\n\nSpecifiying response and predictor:\n\n::: {.cell hash='04_h20_cache/html/unnamed-chunk-3_d9b04fcb2d7eade455601c28b48b6128'}\n\n```{.r .cell-code}\nmy_recipe_object <- recipe(product_backorder ~., data = train_table_final) %>% \n    step_zv(all_predictors()) %>% \n    step_dummy(all_nominal(),-all_outcomes()) %>%\n    prep()\n```\n:::\n\n::: {.cell hash='04_h20_cache/html/unnamed-chunk-4_fa8c8a3b7307c0a9dc5b804c814d7604'}\n\n```{.r .cell-code}\nsummary(my_recipe_object)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"variable\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"type\"],\"name\":[2],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\"role\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"source\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"sku\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"national_inv\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"lead_time\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"in_transit_qty\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"forecast_3_month\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"forecast_6_month\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"forecast_9_month\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"sales_1_month\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"sales_3_month\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"sales_6_month\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"sales_9_month\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"min_bank\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"pieces_past_due\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"perf_6_month_avg\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"perf_12_month_avg\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"local_bo_qty\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"product_backorder\",\"2\":\"<chr [2]>\",\"3\":\"outcome\",\"4\":\"original\"},{\"1\":\"potential_issue_Yes\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"derived\"},{\"1\":\"deck_risk_Yes\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"derived\"},{\"1\":\"oe_constraint_Yes\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"derived\"},{\"1\":\"ppap_risk_Yes\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"derived\"},{\"1\":\"stop_auto_buy_Yes\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"derived\"},{\"1\":\"rev_stop_Yes\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"derived\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell hash='04_h20_cache/html/unnamed-chunk-5_a3fc5c88103074d38fd7ef2cffb88cab'}\n\n```{.r .cell-code}\nglimpse(bake(my_recipe_object,new_data = NULL))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Rows: 14,289\n#> Columns: 23\n#> $ sku                 <dbl> 1872718, 3273776, 3124842, 1626845, 1366494, 21803…\n#> $ national_inv        <dbl> 8, 68, 70, 4, 10, 0, 0, 323, 10, 30, 152, 242, 498…\n#> $ lead_time           <dbl> 4, 8, 8, NA, 12, 15, 4, 0, 10, 8, 52, 4, 20, 8, 4,…\n#> $ in_transit_qty      <dbl> 0, 15, 10, 0, 0, 0, 0, 0, 0, 15, 0, 156, 0, 0, 274…\n#> $ forecast_3_month    <dbl> 0, 169, 60, 0, 0, 0, 18, 0, 0, 54, 0, 204, 0, 0, 6…\n#> $ forecast_6_month    <dbl> 0, 289, 120, 0, 0, 0, 18, 250, 0, 99, 0, 444, 0, 0…\n#> $ forecast_9_month    <dbl> 0, 409, 165, 0, 0, 0, 18, 250, 0, 144, 0, 612, 0, …\n#> $ sales_1_month       <dbl> 0, 52, 16, 0, 0, 0, 0, 0, 0, 16, 0, 70, 0, 10, 199…\n#> $ sales_3_month       <dbl> 0, 135, 59, 2, 0, 4, 0, 0, 0, 43, 12, 236, 0, 54, …\n#> $ sales_6_month       <dbl> 0, 261, 116, 8, 0, 5, 0, 0, 0, 98, 15, 455, 0, 99,…\n#> $ sales_9_month       <dbl> 0, 383, 168, 12, 0, 9, 0, 0, 1, 135, 27, 667, 0, 1…\n#> $ min_bank            <dbl> 0, 78, 29, 1, 1, 0, 0, 0, 0, 18, 0, 84, 0, 21, 231…\n#> $ pieces_past_due     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#> $ perf_6_month_avg    <dbl> 0.73, 1.00, 0.66, -99.00, 0.58, 0.90, 0.22, 0.00, …\n#> $ perf_12_month_avg   <dbl> 0.78, 0.90, 0.66, -99.00, 0.58, 0.91, 0.14, 0.00, …\n#> $ local_bo_qty        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1000, 0,…\n#> $ product_backorder   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#> $ potential_issue_Yes <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#> $ deck_risk_Yes       <dbl> 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,…\n#> $ oe_constraint_Yes   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#> $ ppap_risk_Yes       <dbl> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,…\n#> $ stop_auto_buy_Yes   <dbl> 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n#> $ rev_stop_Yes        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n```\n:::\n:::\n\nStarting H2O:\n\n::: {.cell hash='04_h20_cache/html/unnamed-chunk-6_2646fbb2d6e8154f0342e0a9b9c77297'}\n\n```{.r .cell-code}\nlibrary(h2o)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> \n#> ----------------------------------------------------------------------\n#> \n#> Your next step is to start H2O:\n#>     > h2o.init()\n#> \n#> For H2O package documentation, ask for help:\n#>     > ??h2o\n#> \n#> After starting H2O, you can use the Web UI at http://localhost:54321\n#> For more information visit https://docs.h2o.ai\n#> \n#> ----------------------------------------------------------------------\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> \n#> Attaching package: 'h2o'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> The following objects are masked from 'package:lubridate':\n#> \n#>     day, hour, month, week, year\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> The following objects are masked from 'package:stats':\n#> \n#>     cor, sd, var\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> The following objects are masked from 'package:base':\n#> \n#>     &&, %*%, %in%, ||, apply, as.factor, as.numeric, colnames,\n#>     colnames<-, ifelse, is.character, is.factor, is.numeric, log,\n#>     log10, log1p, log2, round, signif, trunc\n```\n:::\n\n```{.r .cell-code}\nh2o.init()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>  Connection successful!\n#> \n#> R is connected to the H2O cluster: \n#>     H2O cluster uptime:         17 minutes 32 seconds \n#>     H2O cluster timezone:       Europe/Berlin \n#>     H2O data parsing timezone:  UTC \n#>     H2O cluster version:        3.40.0.1 \n#>     H2O cluster version age:    3 months and 26 days \n#>     H2O cluster name:           H2O_started_from_R_milan_hhk744 \n#>     H2O cluster total nodes:    1 \n#>     H2O cluster total memory:   1.90 GB \n#>     H2O cluster total cores:    8 \n#>     H2O cluster allowed cores:  8 \n#>     H2O cluster healthy:        TRUE \n#>     H2O Connection ip:          localhost \n#>     H2O Connection port:        54321 \n#>     H2O Connection proxy:       NA \n#>     H2O Internal Security:      FALSE \n#>     R Version:                  R version 4.3.0 (2023-04-21)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning in h2o.clusterInfo(): \n#> Your H2O cluster version is (3 months and 26 days) old. There may be a newer version available.\n#> Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n```\n:::\n:::\n\n\nRunning AutoML specifying the stopping criterion:\n\n::: {.cell hash='04_h20_cache/html/unnamed-chunk-7_cda459f1686423eec00346c7b298facb'}\n\n```{.r .cell-code}\nlibrary(h2o)\nh2o.init()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>  Connection successful!\n#> \n#> R is connected to the H2O cluster: \n#>     H2O cluster uptime:         39 minutes 56 seconds \n#>     H2O cluster timezone:       Europe/Berlin \n#>     H2O data parsing timezone:  UTC \n#>     H2O cluster version:        3.40.0.1 \n#>     H2O cluster version age:    3 months and 26 days \n#>     H2O cluster name:           H2O_started_from_R_milan_hhk744 \n#>     H2O cluster total nodes:    1 \n#>     H2O cluster total memory:   1.83 GB \n#>     H2O cluster total cores:    8 \n#>     H2O cluster allowed cores:  8 \n#>     H2O cluster healthy:        TRUE \n#>     H2O Connection ip:          localhost \n#>     H2O Connection port:        54321 \n#>     H2O Connection proxy:       NA \n#>     H2O Internal Security:      FALSE \n#>     R Version:                  R version 4.3.0 (2023-04-21)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning in h2o.clusterInfo(): \n#> Your H2O cluster version is (3 months and 26 days) old. There may be a newer version available.\n#> Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n```\n:::\n\n```{.r .cell-code}\nsplit <- h2o.splitFrame(as.h2o(train_table_final), ratios = c(0.75), seed = 42)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\ntrain_h2o_set <- split[[1]]\nvalid_h2o_set <- split[[2]]\ntest_h2o_set  <- as.h2o(test_table_final)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\nresponse <- \"product_backorder\"\npredictors <- setdiff(names(train_h2o_set), response)\n```\n:::\n\n::: {.cell hash='04_h20_cache/html/unnamed-chunk-8_9a27a85db1542ad91d6308e7d523b0a6'}\n\n```{.r .cell-code}\nautoml_h2o_modelling <- h2o.automl(\n  x = predictors,\n  y = response,\n  training_frame    = train_h2o_set,\n  validation_frame  = valid_h2o_set,\n  leaderboard_frame = test_h2o_set,\n  max_runtime_secs  = 60,\n  nfolds            = 5,\n  stopping_metric = \"mae\", stopping_rounds = 3,\n                        stopping_tolerance = 1e-2\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   2%\n#> 12:17:29.782: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n#> 12:17:29.789: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 12:17:29.789: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |====                                                                  |   5%\n#> 12:17:33.316: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 12:17:33.316: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n#> 12:17:33.617: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 12:17:33.617: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |======                                                                |   9%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |===========                                                           |  15%\n#> 12:17:38.75: _train param, Dropping unused columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 12:17:38.75: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n#> 12:17:39.151: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 12:17:39.151: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |=============                                                         |  19%\n#> 12:17:41.818: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 12:17:41.818: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |================                                                      |  22%\n  |                                                                            \n  |==================                                                    |  26%\n#> 12:17:45.717: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 12:17:45.717: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |====================                                                  |  29%\n  |                                                                            \n  |=======================                                               |  32%\n#> 12:17:48.567: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 12:17:48.567: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |=========================                                             |  36%\n#> 12:17:51.781: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 12:17:51.781: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |===========================                                           |  39%\n  |                                                                            \n  |==============================                                        |  43%\n#> 12:17:55.632: _train param, Dropping unused columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 12:17:55.632: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |================================                                      |  46%\n#> 12:17:56.745: _train param, Dropping unused columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 12:17:56.745: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n#> 12:17:58.74: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 12:17:58.74: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |===================================                                   |  49%\n#> 12:17:59.635: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 12:17:59.635: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |=======================================                               |  56%\n#> 12:18:04.366: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 12:18:04.366: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |============================================                          |  63%\n#> 12:18:07.758: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 12:18:07.758: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |===============================================                       |  67%\n#> 12:18:09.972: _train param, Dropping unused columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 12:18:09.972: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |=================================================                     |  70%\n#> 12:18:11.25: _train param, Dropping unused columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 12:18:11.25: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |==================================================================    |  94%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n:::\n\n\nLeaderboard:\n\n::: {.cell hash='04_h20_cache/html/unnamed-chunk-9_71afe2d3b0ba625c6af247234d1071c6'}\n\n```{.r .cell-code}\nautoml_h2o_modelling@leaderboard \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>                                                  model_id      rmse        mse\n#> 1    StackedEnsemble_AllModels_2_AutoML_3_20230604_121729 0.2270740 0.05156262\n#> 2    StackedEnsemble_AllModels_1_AutoML_3_20230604_121729 0.2276583 0.05182829\n#> 3 StackedEnsemble_BestOfFamily_2_AutoML_3_20230604_121729 0.2279641 0.05196765\n#> 4 StackedEnsemble_BestOfFamily_3_AutoML_3_20230604_121729 0.2280226 0.05199432\n#> 5         XGBoost_grid_1_AutoML_3_20230604_121729_model_2 0.2297512 0.05278564\n#> 6                          GBM_4_AutoML_3_20230604_121729 0.2301760 0.05298100\n#>         mae     rmsle mean_residual_deviance\n#> 1 0.1144421 0.1590805             0.05156262\n#> 2 0.1160820 0.1591931             0.05182829\n#> 3 0.1158254 0.1594431             0.05196765\n#> 4 0.1151991 0.1598848             0.05199432\n#> 5 0.1118570 0.1609210             0.05278564\n#> 6 0.1192350 0.1605354             0.05298100\n#> \n#> [25 rows x 6 columns]\n```\n:::\n\n```{.r .cell-code}\nautoml_h2o_modelling@leader\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Model Details:\n#> ==============\n#> \n#> H2ORegressionModel: stackedensemble\n#> Model ID:  StackedEnsemble_AllModels_2_AutoML_3_20230604_121729 \n#> Model Summary for Stacked Ensemble: \n#>                                          key            value\n#> 1                          Stacking strategy cross_validation\n#> 2       Number of base models (used / total)             9/12\n#> 3           # GBM base models (used / total)              4/5\n#> 4       # XGBoost base models (used / total)              3/3\n#> 5           # DRF base models (used / total)              2/2\n#> 6  # DeepLearning base models (used / total)              0/1\n#> 7           # GLM base models (used / total)              0/1\n#> 8                      Metalearner algorithm              GLM\n#> 9         Metalearner fold assignment scheme           Random\n#> 10                        Metalearner nfolds                5\n#> 11                   Metalearner fold_column               NA\n#> 12        Custom metalearner hyperparameters             None\n#> \n#> \n#> H2ORegressionMetrics: stackedensemble\n#> ** Reported on training data. **\n#> \n#> MSE:  0.01999491\n#> RMSE:  0.1414034\n#> MAE:  0.07081871\n#> RMSLE:  0.09971389\n#> Mean Residual Deviance :  0.01999491\n#> \n#> \n#> H2ORegressionMetrics: stackedensemble\n#> ** Reported on validation data. **\n#> \n#> MSE:  0.04926907\n#> RMSE:  0.2219664\n#> MAE:  0.1121348\n#> RMSLE:  0.1567306\n#> Mean Residual Deviance :  0.04926907\n#> \n#> \n#> H2ORegressionMetrics: stackedensemble\n#> ** Reported on cross-validation data. **\n#> ** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n#> \n#> MSE:  0.05076405\n#> RMSE:  0.2253088\n#> MAE:  0.1137115\n#> RMSLE:  0.1585601\n#> Mean Residual Deviance :  0.05076405\n#> \n#> \n#> Cross-Validation Metrics Summary: \n#>                              mean        sd cv_1_valid cv_2_valid cv_3_valid\n#> mae                      0.113692  0.002561   0.114250   0.110499   0.117107\n#> mean_residual_deviance   0.050711  0.002629   0.051282   0.047497   0.054659\n#> mse                      0.050711  0.002629   0.051282   0.047497   0.054659\n#> null_deviance          223.521880 10.802477 232.831180 219.019930 236.307000\n#> r2                       0.512421  0.018897   0.519752   0.539812   0.488705\n#> residual_deviance      109.020850  7.842339 111.795260 100.788520 120.797165\n#> rmse                     0.225131  0.005814   0.226456   0.217938   0.233793\n#> rmsle                    0.158430  0.003556   0.159150   0.153994   0.163547\n#>                        cv_4_valid cv_5_valid\n#> mae                      0.111933   0.114672\n#> mean_residual_deviance   0.049532   0.050584\n#> mse                      0.049532   0.050584\n#> null_deviance          210.162950 219.288330\n#> r2                       0.507744   0.506092\n#> residual_deviance      103.422600 108.300710\n#> rmse                     0.222558   0.224909\n#> rmsle                    0.156461   0.159000\n```\n:::\n\n```{.r .cell-code}\n?h2o.deeplearning\n```\n:::\n\n::: {.cell hash='04_h20_cache/html/unnamed-chunk-10_30f5f7b5a15837e11218b837e581d93a'}\n\n```{.r .cell-code}\nextract_h2o_model <- function(h2o_leaderboard, n = 1, verbose = T) {\n    h2o_model_name <- h2o_leaderboard %>%\n        as.tibble() %>%\n        slice_(n) %>%\n        pull(model_id)\n    \n    if (verbose) message(h2o_model_name)\n    return(h2o_model_name)\n}\n```\n:::\n\n\n\n\nLeader Model Prediction:\n\n::: {.cell hash='04_h20_cache/html/unnamed-chunk-11_f66f36e2dbe1233c9fbc40d7af619e39'}\n\n```{.r .cell-code}\nh2o.init()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>  Connection successful!\n#> \n#> R is connected to the H2O cluster: \n#>     H2O cluster uptime:         3 hours 10 minutes \n#>     H2O cluster timezone:       Europe/Berlin \n#>     H2O data parsing timezone:  UTC \n#>     H2O cluster version:        3.40.0.1 \n#>     H2O cluster version age:    3 months and 26 days \n#>     H2O cluster name:           H2O_started_from_R_milan_hhk744 \n#>     H2O cluster total nodes:    1 \n#>     H2O cluster total memory:   1.75 GB \n#>     H2O cluster total cores:    8 \n#>     H2O cluster allowed cores:  8 \n#>     H2O cluster healthy:        TRUE \n#>     H2O Connection ip:          localhost \n#>     H2O Connection port:        54321 \n#>     H2O Connection proxy:       NA \n#>     H2O Internal Security:      FALSE \n#>     R Version:                  R version 4.3.0 (2023-04-21)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning in h2o.clusterInfo(): \n#> Your H2O cluster version is (3 months and 26 days) old. There may be a newer version available.\n#> Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n```\n:::\n\n```{.r .cell-code}\noptimum_model <- automl_h2o_modelling@leaderboard %>% \n  extract_h2o_model(1) %>% \n  h2o.getModel()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning: `slice_()` was deprecated in dplyr 0.7.0.\n#> ℹ Please use `slice()` instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning: `as.tibble()` was deprecated in tibble 2.0.0.\n#> ℹ Please use `as_tibble()` instead.\n#> ℹ The signature and semantics have changed, see `?as_tibble`.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> StackedEnsemble_AllModels_2_AutoML_3_20230604_121729\n```\n:::\n:::\n\n::: {.cell hash='04_h20_cache/html/unnamed-chunk-12_1162606e676ff4a44ac18833fe6581ff'}\n\n```{.r .cell-code}\nh2o.init()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>  Connection successful!\n#> \n#> R is connected to the H2O cluster: \n#>     H2O cluster uptime:         3 hours 10 minutes \n#>     H2O cluster timezone:       Europe/Berlin \n#>     H2O data parsing timezone:  UTC \n#>     H2O cluster version:        3.40.0.1 \n#>     H2O cluster version age:    3 months and 26 days \n#>     H2O cluster name:           H2O_started_from_R_milan_hhk744 \n#>     H2O cluster total nodes:    1 \n#>     H2O cluster total memory:   1.75 GB \n#>     H2O cluster total cores:    8 \n#>     H2O cluster allowed cores:  8 \n#>     H2O cluster healthy:        TRUE \n#>     H2O Connection ip:          localhost \n#>     H2O Connection port:        54321 \n#>     H2O Connection proxy:       NA \n#>     H2O Internal Security:      FALSE \n#>     R Version:                  R version 4.3.0 (2023-04-21)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning in h2o.clusterInfo(): \n#> Your H2O cluster version is (3 months and 26 days) old. There may be a newer version available.\n#> Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n```\n:::\n\n```{.r .cell-code}\nh20_predictions <- h2o.predict(optimum_model, newdata = as.h2o(test_table_final))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\ntypeof(h20_predictions)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] \"environment\"\n```\n:::\n\n```{.r .cell-code}\nh20_predictions_tbl <- h20_predictions %>% as_tibble()\n```\n:::\n\n::: {.cell hash='04_h20_cache/html/unnamed-chunk-13_cb554c923df8be508c1c6cb79d8cb702'}\n\n```{.r .cell-code}\nglimpse(h20_predictions_tbl)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Rows: 4,764\n#> Columns: 1\n#> $ predict <dbl> 0.8564444, 0.4372353, 0.7754818, 0.5424764, 0.1062112, 0.51310…\n```\n:::\n:::\n\n\nLeader model save to local memory:\n\n::: {.cell hash='04_h20_cache/html/unnamed-chunk-14_aa787d0b7e7d82604a144b171a82670f'}\n\n```{.r .cell-code}\noptimum_model %>% h2o.saveModel(path = \"Challenge_H20_Leader_Model_20230604\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] \"/Users/milan/Documents/study/SEM2/BDS/grading/ss23-bdml-milan-15697/content/01_journal/Challenge_H20_Leader_Model_20230604/StackedEnsemble_AllModels_2_AutoML_3_20230604_121729\"\n```\n:::\n:::\n\nFooter",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}